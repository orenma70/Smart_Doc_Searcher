def perform_search(query: str, directory_path: str = ""):
    """
    Performs an aggressive RAG search: reads all PDF content in the directory,
    combines it, and sends the unified context to Gemini for analysis.
    """

    try:
        storage_client = storage.Client()
        gemini_client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
    except Exception as e:
        # אם יש בעיה באתחול (API Key או הרשאות), נחזיר שגיאה נשלטת (500)
        return {"status": "Error", "details": f"Failed to initialize clients: {e}"}

    bucket = storage_client.bucket(BUCKET_NAME)

    # List all relevant files in the specified directory_path
    blobs = list(bucket.list_blobs(prefix=directory_path + "/"))
    pdf_blobs = [b for b in blobs if b.name.lower().endswith('.pdf')]

    if not pdf_blobs:
        return {"status": "Error", "details": f"No PDF files found in GCS folder: {directory_path}"}

    # --- AGGRESSIVE RAG: Read ALL documents concurrently ---

    # Use ThreadPoolExecutor to speed up downloading and processing all PDFs
    all_context_text = ""
    with ThreadPoolExecutor(max_workers=5) as executor:
        # Map the download_and_process_file function to all PDF blobs
        future_results = executor.map(download_and_process_file, pdf_blobs)

        # Combine all extracted text into one large context string
        for text_content in future_results:
            if text_content:
                all_context_text += text_content + "\n\n---\n\n"

    if not all_context_text.strip():
        return {"status": "Error", "details": "Could not extract readable text from any PDF in the directory."}

    # --- Gemini Analysis ---

    # System Instruction: Guiding the model's persona and output
    system_instruction = (
        "אתה אנליסט מסמכים מקצועי. התשובה שלך צריכה להיות עברית רהוטה וברורה. "
        "השתמש אך ורק במידע שסופק בתוך 'CONTEXT' כדי לענות על שאלת המשתמש. "
        "אם המידע אינו קיים ב-CONTEXT, ענה: 'המידע לגבי [שאלה ספציפית] אינו נמצא במסמכים שסופקו'."
    )

    # User Prompt: The combined context and the query
    user_prompt = (
        f"CONTEXT:\n\n{all_context_text}"
        f"\n\n---"
        f"\n\nשאלה אנליטית: {query}"
    )

    try:
        # Call Gemini API
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=user_prompt,
            system_instruction=system_instruction
        )

        # Success: Return the full analytical response
        return {
            "query": query,
            "status": "Success (RAG)",
            "response": response.text,
            "sources": []  # No specific sources tracking in Aggressive RAG
        }

    except Exception as e:
        # Handle API errors (e.g., key expired, invalid request)
        print(f"Gemini API Error or runtime error: {e}")
        return {
            "status": "API Error",
            "details": f"Check your GEMINI_API_KEY, model name, and request. Details: {e}"
        }


# --- Flask Routes ---

@app.route("/search", methods=["POST"])
def search():
    """Endpoint for performing the RAG search."""
    try:
        data = request.get_json()
        query = data.get("query", "")
        directory_path = data.get("directory_path", "")

        if not query or not directory_path:
            return jsonify({"status": "Error", "details": "Missing 'query' or 'directory_path' in request."}), 400

        result = perform_search(query, directory_path)
        return jsonify(result)

    except Exception as e:
        print(f"Request handling error: {e}")
        return jsonify({"status": "Error", "details": f"Internal server error: {e}"}), 500

